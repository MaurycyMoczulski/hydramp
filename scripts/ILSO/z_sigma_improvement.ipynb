{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto(\n",
    "    gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.8),\n",
    ")\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "tf.compat.v1.keras.backend.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import random\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from amp.utils.basic_model_serializer import load_master_model_components\n",
    "from amp.models.decoders import amp_expanded_decoder\n",
    "from amp.models.encoders import amp_expanded_encoder\n",
    "from amp.models.master import master\n",
    "from amp.utils import basic_model_serializer, callback, generator\n",
    "import amp.data_utils.data_loader as data_loader\n",
    "from amp.config import hydra, pepcvae, basic\n",
    "from amp.data_utils.sequence import pad, to_one_hot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "from keras import backend, layers, activations, Model\n",
    "from amp.utils import metrics as amp_metrics\n",
    "from keras import models as m\n",
    "from keras.optimizers import Adam\n",
    "from tqdm import tqdm\n",
    "from joblib import dump, load\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "params = {'axes.labelsize': 8,\n",
    "         'axes.titlesize': 8,\n",
    "         'xtick.labelsize': 8,\n",
    "         'ytick.labelsize': 8}\n",
    "plt.rcParams.update(params)\n",
    "plt.rc('text', usetex=False)\n",
    "sns.set_style('whitegrid', {'grid.color': '.95', 'axes.spines.right': False, 'axes.spines.top': False})\n",
    "# sns.set_context(\"notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from amp.config import MIN_LENGTH, MAX_LENGTH, LATENT_DIM, MIN_KL, RCL_WEIGHT, HIDDEN_DIM, MAX_TEMPERATURE\n",
    "\n",
    "input_to_encoder = layers.Input(shape=(MAX_LENGTH,))\n",
    "input_to_decoder = layers.Input(shape=(LATENT_DIM+2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_generated_peptide(encoded_peptide):\n",
    "    alphabet = list('ACDEFGHIKLMNPQRSTVWY')\n",
    "    return ''.join([alphabet[el - 1] if el != 0 else \"\" for el in encoded_peptide[0].argmax(axis=1)])\n",
    "\n",
    "def translate_peptide(encoded_peptide):\n",
    "    alphabet = list('ACDEFGHIKLMNPQRSTVWY')\n",
    "    return ''.join([alphabet[el-1] if el != 0 else \"\" for el in encoded_peptide])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    'HydrAMP_each_epoch',\n",
    "    'HydrAMP_pure',\n",
    "    'HydrAMP_pure_extend',\n",
    "    'HydrAMP_restarting_phase_2',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epochs = {\n",
    "    'HydrAMP_each_epoch': 11,\n",
    "    'HydrAMP_pure': 10,\n",
    "    'HydrAMP_pure_extend': 2,\n",
    "    'HydrAMP_restarting_phase_2': 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bms = basic_model_serializer.BasicModelSerializer()\n",
    "amp_classifier = bms.load_model('../../models/amp_classifier')\n",
    "amp_classifier_model = amp_classifier()\n",
    "mic_classifier = bms.load_model('../../models/mic_classifier/')\n",
    "mic_classifier_model = mic_classifier() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(seed)\n",
    "data_manager = data_loader.AMPDataManager(\n",
    "    '../../data/unlabelled_positive.csv',\n",
    "    '../../data/unlabelled_negative.csv',\n",
    "    min_len=MIN_LENGTH,\n",
    "    max_len=MAX_LENGTH)\n",
    "\n",
    "amp_x, amp_y = data_manager.get_merged_data()\n",
    "amp_x_train, amp_x_test, amp_y_train, amp_y_test = train_test_split(amp_x, amp_y, test_size=0.1, random_state=36)\n",
    "amp_x_train, amp_x_val, amp_y_train, amp_y_val = train_test_split(amp_x_train, amp_y_train, test_size=0.2, random_state=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict the length\n",
    "ecoli_df = pd.read_csv('../../data/mic_data.csv')\n",
    "mask = (ecoli_df['sequence'].str.len() <= MAX_LENGTH) & (ecoli_df['sequence'].str.len() >= MIN_LENGTH)\n",
    "ecoli_df = ecoli_df.loc[mask]\n",
    "mic_x = pad(to_one_hot(ecoli_df['sequence']))\n",
    "mic_y = ecoli_df.value\n",
    "\n",
    "mic_x_train, mic_x_test, mic_y_train, mic_y_test = train_test_split(mic_x, mic_y, test_size=0.1, random_state=36)\n",
    "mic_x_train, mic_x_val, mic_y_train, mic_y_val = train_test_split(mic_x_train, mic_y_train, test_size=0.2, random_state=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1319/1319 [==============================] - 0s 261us/step\n",
      "1253/1253 [==============================] - 0s 119us/step\n",
      "1253/1253 [==============================] - 0s 135us/step\n",
      "1319/1319 [==============================] - 0s 95us/step\n"
     ]
    }
   ],
   "source": [
    "n=64\n",
    "\n",
    "pos = np.vstack([amp_x_test[amp_y_test == 1], mic_x_test[mic_y_test < 1.5]])\n",
    "neg = np.vstack([amp_x_test[amp_y_test == 0], mic_x_test[mic_y_test > 1.5]])\n",
    "\n",
    "pos_amp = amp_classifier_model.predict(pos, verbose=1).reshape(len(pos))\n",
    "neg_mic = mic_classifier_model.predict(neg, verbose=1).reshape(len(neg))\n",
    "neg_amp = amp_classifier_model.predict(neg, verbose=1).reshape(len(neg))\n",
    "pos_mic = mic_classifier_model.predict(pos, verbose=1).reshape(len(pos))\n",
    "\n",
    "pos = np.vstack([pos] * n).reshape(-1, 25)\n",
    "pos_amp = np.vstack([pos_amp] * n).reshape(-1, 1)\n",
    "pos_mic = np.vstack([pos_mic] * n).reshape(-1, 1)\n",
    "neg = np.vstack([neg] * n).reshape(-1, 25)\n",
    "neg_amp = np.vstack([neg_amp] * n).reshape(-1, 1)\n",
    "neg_mic = np.vstack([neg_mic] * n).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_z_sigma(x):\n",
    "    inputs = layers.Input(shape=(25,))\n",
    "    z_mean, z_sigma, z = AMPMaster.encoder.output_tensor(inputs)\n",
    "    temp_encoder = m.Model(inputs, [z_mean, z_sigma, z])\n",
    "    z_mean, z_sigma, z = temp_encoder.predict(x) \n",
    "    return np.exp(z_sigma / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def improve(seq, amp, mic, z_sigma, temp=0.0):\n",
    "    z = encoder_model.predict(seq, batch_size=5000)\n",
    "    noise = np.random.normal(loc=0, scale=temp*z_sigma, size=z.shape)\n",
    "    encoded = z + noise\n",
    "    conditioned = np.hstack([\n",
    "        encoded,\n",
    "        np.ones((len(seq), 1)),\n",
    "        np.ones((len(seq), 1)),\n",
    "    ])\n",
    "    decoded = decoder_model.predict(conditioned, batch_size=5000)\n",
    "    new_peptides = np.argmax(decoded, axis=2)\n",
    "    new_amp = amp_classifier_model.predict(new_peptides, batch_size=5000)\n",
    "    new_mic = mic_classifier_model.predict(new_peptides, batch_size=5000)                                                                             \n",
    "    \n",
    "    # RELATIVE\n",
    "    rel_better = new_amp > amp.reshape(-1, 1)\n",
    "    rel_better = rel_better & (new_mic > mic.reshape(-1, 1))\n",
    "    rel_better = np.logical_or.reduce(rel_better, axis=1)\n",
    "    rel_improved = new_peptides[np.where(rel_better), :].reshape(-1, 25)\n",
    "    before_rel_improve = seq[np.where(rel_better), :].reshape(-1, 25)\n",
    "    \n",
    "    # ABSOLUTE\n",
    "    abs_better = new_amp >= 0.8\n",
    "    abs_better = abs_better & (new_mic > 0.5)\n",
    "    abs_better = np.logical_or.reduce(abs_better, axis=1)\n",
    "    abs_improved = new_peptides[np.where(abs_better), :].reshape(-1, 25)\n",
    "    before_abs_improve = seq[np.where(abs_better), :].reshape(-1, 25)\n",
    "    \n",
    "    return {\n",
    "        'new_peptides': new_peptides,\n",
    "        'rel_improved': rel_improved,\n",
    "        'abs_improved': abs_improved,\n",
    "        'before_rel_improve': before_rel_improve,\n",
    "        'before_abs_improve': before_abs_improve, \n",
    "        'new_amp': new_amp,\n",
    "        'new_mic': new_mic,\n",
    "        }                                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = backend.variable(1.0, name=\"temperature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models[INDEX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking <tf.Variable 'temperature:0' shape=() dtype=float32, numpy=0.66574216> temperature\n",
      "tracking <tf.Variable 'temperature:0' shape=() dtype=float32, numpy=1.0> temperature\n"
     ]
    }
   ],
   "source": [
    "AMPMaster = bms.load_model(f'../../models/ilso_models/{model}/{best_epochs[model]}')\n",
    "encoder_model =  AMPMaster.encoder(input_to_encoder)\n",
    "AMPMaster.decoder.activation.temperature = tau\n",
    "decoder_model = AMPMaster.decoder(input_to_decoder)             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 peptide improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshteinDistanceDP(token1, token2):\n",
    "    distances = np.zeros((len(token1) + 1, len(token2) + 1))\n",
    "\n",
    "    for t1 in range(len(token1) + 1):\n",
    "        distances[t1][0] = t1\n",
    "\n",
    "    for t2 in range(len(token2) + 1):\n",
    "        distances[0][t2] = t2\n",
    "        \n",
    "    a = 0\n",
    "    b = 0\n",
    "    c = 0\n",
    "    \n",
    "    for t1 in range(1, len(token1) + 1):\n",
    "        for t2 in range(1, len(token2) + 1):\n",
    "            if (token1[t1-1] == token2[t2-1]):\n",
    "                distances[t1][t2] = distances[t1 - 1][t2 - 1]\n",
    "            else:\n",
    "                a = distances[t1][t2 - 1]\n",
    "                b = distances[t1 - 1][t2]\n",
    "                c = distances[t1 - 1][t2 - 1]\n",
    "                \n",
    "                if (a <= b and a <= c):\n",
    "                    distances[t1][t2] = a + 1\n",
    "                elif (b <= a and b <= c):\n",
    "                    distances[t1][t2] = b + 1\n",
    "                else:\n",
    "                    distances[t1][t2] = c + 1\n",
    "\n",
    "    return distances[len(token1)][len(token2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique(x):\n",
    "    if x.shape[0] > 1:\n",
    "        return np.unique(x, axis=0)\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "peptides = [\n",
    "    \"ILRWPWWPWRRK\", # Omiganan (MBI-226)\n",
    "    \"AKRHHGYKRKFH\", # Demegen (P-113)\n",
    "    \"GRRRRSVQWCA\", # hLF1-11\n",
    "    \"KNKRKRRRRRRGGRRRR\", # Mel4\n",
    "    \"MPKEKVFLKIEKMGRNIRN\", # Vishnu3 (HB-107)\n",
    "]\n",
    "\n",
    "n = 100000\n",
    "# temps =  np.linspace(0,5,num=21)\n",
    "temps = [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [02:02<00:00, 24.47s/it]\n"
     ]
    }
   ],
   "source": [
    "no_analogues = []\n",
    "levenshtein = []\n",
    "all_analogues = []\n",
    "\n",
    "for peptide in tqdm(peptides):\n",
    "    pep = pad(to_one_hot([peptide]))\n",
    "    amp = amp_classifier_model.predict(pep)\n",
    "    mic = mic_classifier_model.predict(pep)\n",
    "    z_sigma = get_z_sigma(pep)\n",
    "    \n",
    "    pep = np.vstack([pep] * n).reshape(-1, 25)\n",
    "    amp = np.vstack([amp] * n)\n",
    "    mic = np.vstack([mic] * n)\n",
    "    \n",
    "    analogues = []\n",
    "    ld = []\n",
    "    \n",
    "    for temp in temps:\n",
    "        analogue_batch = get_unique(improve(pep, amp, mic, z_sigma, temp=temp)['abs_improved'])\n",
    "        analogues.append(analogue_batch)\n",
    "        ld.append([levenshteinDistanceDP(peptide, translate_peptide(x)) for x in analogue_batch])\n",
    "        all_analogues.extend([translate_peptide(x) for x in analogue_batch])\n",
    "\n",
    "    no_analogues.append([len(x) for x in analogues])\n",
    "    levenshtein.append(ld)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(f\"../../results/ilso_results/{model}.txt\", np.array(all_analogues), delimiter=\",\")\n",
    "pd.DataFrame({\"sequence\": all_analogues}).to_csv(f\"../../results/ilso_results/{model}.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
